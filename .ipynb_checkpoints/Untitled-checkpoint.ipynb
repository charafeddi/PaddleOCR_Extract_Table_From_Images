{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2b41c22-4c8c-4f90-9735-336d1a1a2792",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytesseract\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimutils\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pytesseract import Output\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to input image to be OCR'd\")\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "\thelp=\"path to output CSV file\")\n",
    "ap.add_argument(\"-c\", \"--min-conf\", type=int, default=0,\n",
    "\thelp=\"minimum confidence value to filter weak text detection\")\n",
    "ap.add_argument(\"-d\", \"--dist-thresh\", type=float, default=25.0,\n",
    "\thelp=\"distance threshold cutoff for clustering\")\n",
    "ap.add_argument(\"-s\", \"--min-size\", type=int, default=2,\n",
    "\thelp=\"minimum cluster size (i.e., # of entries in column)\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# set a seed for our random number generator\n",
    "np.random.seed(42)\n",
    "# load the input image and convert it to grayscale\n",
    "image = cv2.imread(args[\"image\"])\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# initialize a rectangular kernel that is ~5x wider than it is tall,\n",
    "# then smooth the image using a 3x3 Gaussian blur and then apply a\n",
    "# blackhat morphological operator to find dark regions on a light\n",
    "# background\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (51, 11))\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
    "# compute the Scharr gradient of the blackhat image and scale the\n",
    "# result into the range [0, 255]\n",
    "grad = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "grad = np.absolute(grad)\n",
    "(minVal, maxVal) = (np.min(grad), np.max(grad))\n",
    "grad = (grad - minVal) / (maxVal - minVal)\n",
    "grad = (grad * 255).astype(\"uint8\")\n",
    "# apply a closing operation using the rectangular kernel to close\n",
    "# gaps in between characters, apply Otsu's thresholding method, and\n",
    "# finally a dilation operation to enlarge foreground regions\n",
    "grad = cv2.morphologyEx(grad, cv2.MORPH_CLOSE, kernel)\n",
    "thresh = cv2.threshold(grad, 0, 255,\n",
    "\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "thresh = cv2.dilate(thresh, None, iterations=3)\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "\n",
    "# find contours in the thresholded image and grab the largest one,\n",
    "# which we will assume is the stats table\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "tableCnt = max(cnts, key=cv2.contourArea)\n",
    "# compute the bounding box coordinates of the stats table and extract\n",
    "# the table from the input image\n",
    "(x, y, w, h) = cv2.boundingRect(tableCnt)\n",
    "table = image[y:y + h, x:x + w]\n",
    "# show the original input image and extracted table to our screen\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"Table\", table)\n",
    "\n",
    "# set the PSM mode to detect sparse text, and then localize text in\n",
    "# the table\n",
    "options = \"--psm 6\"\n",
    "results = pytesseract.image_to_data(\n",
    "\tcv2.cvtColor(table, cv2.COLOR_BGR2RGB),\n",
    "\tconfig=options,\n",
    "\toutput_type=Output.DICT)\n",
    "# initialize a list to store the (x, y)-coordinates of the detected\n",
    "# text along with the OCR'd text itself\n",
    "coords = []\n",
    "ocrText = []\n",
    "\n",
    "# loop over each of the individual text localizations\n",
    "for i in range(0, len(results[\"text\"])):\n",
    "\t# extract the bounding box coordinates of the text region from\n",
    "\t# the current result\n",
    "\tx = results[\"left\"][i]\n",
    "\ty = results[\"top\"][i]\n",
    "\tw = results[\"width\"][i]\n",
    "\th = results[\"height\"][i]\n",
    "\t# extract the OCR text itself along with the confidence of the\n",
    "\t# text localization\n",
    "\ttext = results[\"text\"][i]\n",
    "\tconf = int(results[\"conf\"][i])\n",
    "\t# filter out weak confidence text localizations\n",
    "\tif conf > args[\"min_conf\"]:\n",
    "\t\t# update our text bounding box coordinates and OCR'd text,\n",
    "\t\t# respectively\n",
    "\t\tcoords.append((x, y, w, h))\n",
    "\t\tocrText.append(text)\n",
    "\n",
    "# extract all x-coordinates from the text bounding boxes, setting the\n",
    "# y-coordinate value to zero\n",
    "xCoords = [(c[0], 0) for c in coords]\n",
    "# apply hierarchical agglomerative clustering to the coordinates\n",
    "clustering = AgglomerativeClustering(\n",
    "\tn_clusters=None,\n",
    "\taffinity=\"manhattan\",\n",
    "\tlinkage=\"complete\",\n",
    "\tdistance_threshold=args[\"dist_thresh\"])\n",
    "clustering.fit(xCoords)\n",
    "# initialize our list of sorted clusters\n",
    "sortedClusters = []\n",
    "\n",
    "# loop over all clusters\n",
    "for l in np.unique(clustering.labels_):\n",
    "\t# extract the indexes for the coordinates belonging to the\n",
    "\t# current cluster\n",
    "\tidxs = np.where(clustering.labels_ == l)[0]\n",
    "\t# verify that the cluster is sufficiently large\n",
    "\tif len(idxs) > args[\"min_size\"]:\n",
    "\t\t# compute the average x-coordinate value of the cluster and\n",
    "\t\t# update our clusters list with the current label and the\n",
    "\t\t# average x-coordinate\n",
    "\t\tavg = np.average([coords[i][0] for i in idxs])\n",
    "\t\tsortedClusters.append((l, avg))\n",
    "# sort the clusters by their average x-coordinate and initialize our\n",
    "# data frame\n",
    "sortedClusters.sort(key=lambda x: x[1])\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop over the clusters again, this time in sorted order\n",
    "for (l, _) in sortedClusters:\n",
    "\t# extract the indexes for the coordinates belonging to the\n",
    "\t# current cluster\n",
    "\tidxs = np.where(clustering.labels_ == l)[0]\n",
    "\t# extract the y-coordinates from the elements in the current\n",
    "\t# cluster, then sort them from top-to-bottom\n",
    "\tyCoords = [coords[i][1] for i in idxs]\n",
    "\tsortedIdxs = idxs[np.argsort(yCoords)]\n",
    "\t# generate a random color for the cluster\n",
    "\tcolor = np.random.randint(0, 255, size=(3,), dtype=\"int\")\n",
    "\tcolor = [int(c) for c in color]\n",
    "\n",
    "# replace NaN values with an empty string and then show a nicely\n",
    "# formatted version of our multi-column OCR'd text\n",
    "df.fillna(\"\", inplace=True)\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"psql\"))\n",
    "# write our table to disk as a CSV file\n",
    "print(\"[INFO] saving CSV file to disk...\")\n",
    "df.to_csv(args[\"output\"], index=False)\n",
    "# show the output image after performing multi-column OCR\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
